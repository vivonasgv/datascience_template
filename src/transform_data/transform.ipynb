{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "referenced-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import sys\n",
    "import json\n",
    "import plotly.express as px\n",
    "\n",
    "sys.path.append(\"../modules\")\n",
    "from data_manager import DataManager\n",
    "#from feature_manager import FeatureManger\n",
    "\n",
    "import toniq\n",
    "\n",
    "tsu = toniq.SparkUtils()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-colony",
   "metadata": {},
   "source": [
    "## Setup Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "statutory-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "\"provider\": \"gcp\",\n",
    "\"verbose\": False,\n",
    "\"gt_column\": \"income\",\n",
    "\"data\":\n",
    "\n",
    "{\n",
    "    \"load\":\n",
    "        {\n",
    "             mode: {\"name\": f\"income_raw_data_{mode}\", \"store\": \"data\", \"partition\": None}\n",
    "             for mode in [\"train\", \"test\"]\n",
    "\n",
    "        }, \n",
    "\n",
    "\n",
    "    \"save\":\n",
    "        {\n",
    "             mode: {\"name\": f\"income_transformed_data_{mode}\", \"store\": \"feature\", \"partition\":mode}\n",
    "             for mode in [\"train\", \"test\"]\n",
    "\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-globe",
   "metadata": {},
   "source": [
    "## Initialize DataManger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "included-breath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_endpoint is 10.2.3.167:9000\n"
     ]
    }
   ],
   "source": [
    "dm = DataManager(provider=config[\"provider\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-championship",
   "metadata": {},
   "source": [
    "## Load Raw Data into Toniq Data Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "suspected-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfs = {}\n",
    "for mode, load_data_args in config[\"data\"][\"load\"].items():\n",
    "    dfs[mode] = dm.load_table(**load_data_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "textile-hebrew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>58</td>\n",
       "      <td>?</td>\n",
       "      <td>299831</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>lt 50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>238588</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>lt 50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>205947</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>lt 50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>56</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>186651</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>lt 50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "      <td>Private</td>\n",
       "      <td>43311</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>lt 50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>8111</td>\n",
       "      <td>41</td>\n",
       "      <td>?</td>\n",
       "      <td>45186</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>lt 50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>8114</td>\n",
       "      <td>17</td>\n",
       "      <td>Private</td>\n",
       "      <td>194946</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>lt 50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>8127</td>\n",
       "      <td>18</td>\n",
       "      <td>Private</td>\n",
       "      <td>137363</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>lt 50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269</th>\n",
       "      <td>8134</td>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>143078</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>lt 50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3270</th>\n",
       "      <td>8140</td>\n",
       "      <td>18</td>\n",
       "      <td>Private</td>\n",
       "      <td>216540</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>lt 50k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3271 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  age         workclass  fnlwgt     education  education_num  \\\n",
       "0        13   58                 ?  299831       HS-grad              9   \n",
       "1        21   34           Private  238588  Some-college             10   \n",
       "2        24   25           Private  205947     Bachelors             13   \n",
       "3        31   56  Self-emp-not-inc  186651          11th              7   \n",
       "4        34   26           Private   43311       HS-grad              9   \n",
       "...     ...  ...               ...     ...           ...            ...   \n",
       "3266   8111   41                 ?   45186  Some-college             10   \n",
       "3267   8114   17           Private  194946          11th              7   \n",
       "3268   8127   18           Private  137363  Some-college             10   \n",
       "3269   8134   30           Private  143078   Prof-school             15   \n",
       "3270   8140   18           Private  216540          11th              7   \n",
       "\n",
       "          marital_status       occupation   relationship   race     sex  \\\n",
       "0     Married-civ-spouse                ?        Husband  White    Male   \n",
       "1          Never-married    Other-service      Own-child  Black  Female   \n",
       "2     Married-civ-spouse   Prof-specialty        Husband  White    Male   \n",
       "3                Widowed    Other-service      Unmarried  White  Female   \n",
       "4               Divorced  Exec-managerial      Unmarried  White  Female   \n",
       "...                  ...              ...            ...    ...     ...   \n",
       "3266  Married-civ-spouse                ?        Husband  White    Male   \n",
       "3267       Never-married    Other-service      Own-child  White  Female   \n",
       "3268       Never-married    Other-service      Own-child  White  Female   \n",
       "3269       Never-married   Prof-specialty  Not-in-family  White    Male   \n",
       "3270       Never-married     Craft-repair      Own-child  White    Male   \n",
       "\n",
       "      capital_gain  capital_loss  hours_per_week native_country  income  \n",
       "0                0             0              35  United-States  lt 50k  \n",
       "1                0             0              35  United-States  lt 50k  \n",
       "2                0             0              40  United-States  lt 50k  \n",
       "3                0             0              50  United-States  lt 50k  \n",
       "4                0             0              40  United-States  lt 50k  \n",
       "...            ...           ...             ...            ...     ...  \n",
       "3266             0             0              40  United-States  lt 50k  \n",
       "3267             0             0              20  United-States  lt 50k  \n",
       "3268             0             0              20  United-States  lt 50k  \n",
       "3269             0             0              40  United-States  lt 50k  \n",
       "3270             0             0              40  United-States  lt 50k  \n",
       "\n",
       "[3271 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[mode].sample(0.2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-thought",
   "metadata": {},
   "source": [
    "### Find a Map betwen the Columns and the Column Dtypes and Vice Versa\n",
    "\n",
    "- We want to find a map betweeen each column and their data type such that\n",
    "    - string can be converted to categorical varaibles\n",
    "    - bigint/floats can be converted into continuous variables given high enough cardinality (aka more unique values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "grand-president",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column to Type Map \n",
      "\n",
      "\n",
      " {\n",
      "    \"index\": \"bigint\",\n",
      "    \"age\": \"bigint\",\n",
      "    \"workclass\": \"string\",\n",
      "    \"fnlwgt\": \"bigint\",\n",
      "    \"education\": \"string\",\n",
      "    \"education_num\": \"bigint\",\n",
      "    \"marital_status\": \"string\",\n",
      "    \"occupation\": \"string\",\n",
      "    \"relationship\": \"string\",\n",
      "    \"race\": \"string\",\n",
      "    \"sex\": \"string\",\n",
      "    \"capital_gain\": \"bigint\",\n",
      "    \"capital_loss\": \"bigint\",\n",
      "    \"hours_per_week\": \"bigint\",\n",
      "    \"native_country\": \"string\",\n",
      "    \"income\": \"string\"\n",
      "} \n",
      "\n",
      "\n",
      " Types to Column(s) Map \n",
      "\n",
      " {\n",
      "    \"bigint\": [\n",
      "        \"index\",\n",
      "        \"age\",\n",
      "        \"fnlwgt\",\n",
      "        \"education_num\",\n",
      "        \"capital_gain\",\n",
      "        \"capital_loss\",\n",
      "        \"hours_per_week\"\n",
      "    ],\n",
      "    \"string\": [\n",
      "        \"workclass\",\n",
      "        \"education\",\n",
      "        \"marital_status\",\n",
      "        \"occupation\",\n",
      "        \"relationship\",\n",
      "        \"race\",\n",
      "        \"sex\",\n",
      "        \"native_country\",\n",
      "        \"income\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "df = dfs[\"train\"]\n",
    "\n",
    "col2dtype = {col:dtype for col, dtype in df.dtypes}\n",
    "dtype2col = {}\n",
    "\n",
    "for col, dtype in col2dtype.items():\n",
    "    if dtype in dtype2col:\n",
    "        dtype2col[dtype] += [col]\n",
    "    else:\n",
    "        dtype2col[dtype] = [col]\n",
    "        \n",
    "\n",
    "print(f\"Column to Type Map \\n\\n\\n\",\n",
    "      json.dumps(col2dtype,indent=4),\n",
    "      \"\\n\\n\\n Types to Column(s) Map \\n\\n\", \n",
    "      json.dumps(dtype2col, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-canvas",
   "metadata": {},
   "source": [
    "## Understanding the Data\n",
    "\n",
    "- Visualizing the Distribution of Each Column from the Training Set Only\n",
    "- This allows us to observe any need for what tranformations we need\n",
    "\n",
    "**The Goal**\n",
    "- Transform Continuous Features into Standard Normal Distributions\n",
    "- Transform Categorical Features into One-Hot Encodings (Or Categorical if you want to get fancy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-wales",
   "metadata": {},
   "source": [
    "### Feature Historgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fitted-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"verbose\"]:\n",
    "    for column in df.columns:\n",
    "        tmp_df = df.sample(0.1).toPandas()\n",
    "        fig = px.histogram(tmp_df, x=column)\n",
    "        fig.update_layout(title=column)\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-passport",
   "metadata": {},
   "source": [
    "## Building the Transformation Pipeline\n",
    "\n",
    "- Categorical Variables:\n",
    "    - StringIndex and OnehotCode\n",
    "- Continuous Variables\n",
    "    - Scalar Standardize\n",
    "    \n",
    "**Assumption/Limitation/Warning**\n",
    "   - For Simplicity, all bigint/float columns are treated as continuous\n",
    "   - All strings are categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "portuguese-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StandardScaler, StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "col2pipeline = {}\n",
    "\n",
    "pipeline_list = []\n",
    "categorical_input_list = []\n",
    "gt_column = \"income\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "User inputs N blocks of a transformation\n",
    "user can save the state of this in s3\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "One Hot Encode Categorical Variables\n",
    "\n",
    "\"\"\"\n",
    "for col in dtype2col[\"string\"]: \n",
    "    if col == gt_column:\n",
    "        # just return the index for the ground truth column\n",
    "        pipeline_list.append(StringIndexer(inputCol=col, outputCol = f\"label\", handleInvalid=\"keep\"))\n",
    "        \n",
    "    else:\n",
    "        # get the index of the category\n",
    "        pipeline_list.append(StringIndexer(inputCol=col, outputCol = f\"{col}_index_tmp\"))\n",
    "        \n",
    "        # one hot encode the string index\n",
    "        pipeline_list.append(OneHotEncoder(inputCol=f\"{col}_index_tmp\", outputCol=f\"{col}_ohe_tmp\"))\n",
    "        categorical_input_list.append(f\"{col}_ohe_tmp\")\n",
    "        \n",
    "pipeline_list.append(VectorAssembler(inputCols=categorical_input_list, outputCol=f\"cat_features_tmp\"))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Standardize Continuous Variables\n",
    "\n",
    "Assumption/Limitation\n",
    "\n",
    "- For Simplicity, all bigint/float columns are treated as continuous\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "pipeline_list.append(VectorAssembler(inputCols = dtype2col[\"bigint\"], outputCol = \"cont_features_tmp\")) \n",
    "pipeline_list.append(StandardScaler(inputCol = \"cont_features_tmp\", outputCol = \"cont_features_standardized_tmp\"))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Vector Assemble Continous and Cateogrical Variables into one feature vector \n",
    "\"\"\"\n",
    "\n",
    "pipeline_list.append(VectorAssembler(inputCols = [\"cat_features_tmp\", \"cont_features_standardized_tmp\"], outputCol = \"features\" ))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Create the preprocessing pipeline pipeline \n",
    "\n",
    "\"\"\"\n",
    "transform_pipeline = Pipeline(stages= pipeline_list)\n",
    "\n",
    "'''Fit on TRAIN ONLY'''\n",
    "transform_pipeline = transform_pipeline.fit(dfs[\"train\"])\n",
    "\n",
    "'''Transform on TRAIN and TEST'''\n",
    "transformed_dfs = {split: transform_pipeline.transform(df).select(\"index\",\"features\", \"label\")\n",
    "                           for split, df in dfs.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-farming",
   "metadata": {},
   "source": [
    "## Saved Processed Transformations to Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "introductory-payroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Toniq Table (income_transformed_data_train)\n",
      "Saved Toniq Table (income_transformed_data_test)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for mode, save_data_arg in config[\"data\"][\"save\"].items():\n",
    "    dm.write_table(df = transformed_dfs[mode], **save_data_arg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-niger",
   "metadata": {},
   "source": [
    "## Stop Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "common-telling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_endpoint is 10.2.3.167:9000\n"
     ]
    }
   ],
   "source": [
    "dm.store.stop_spark()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toniq-python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
