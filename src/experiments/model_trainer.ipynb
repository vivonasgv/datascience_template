{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "green-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import sys\n",
    "import json\n",
    "import plotly.express as px\n",
    "\n",
    "sys.path.append(\"../modules\")\n",
    "from data_manager import DataManager\n",
    "\n",
    "\n",
    "import pyspark.ml\n",
    "import pyspark.sql.functions as f\n",
    "import pyspark.sql.types as t\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "import toniq\n",
    "import hyperopt\n",
    "from hyperopt import hp\n",
    "\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "celtic-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    " def calculate_metrics( df):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        define your own metrics to evaluate cross validation\n",
    "        \n",
    "        :params:\n",
    "        \n",
    "        df: dataframe containing {aprediction} and {label} columns\n",
    "        \n",
    "        :returns:\n",
    "        \n",
    "        confusion matrix\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        # turn gt into label\n",
    "        preds_and_labels = df.select('prediction',f.col('label').cast(t.FloatType()))\n",
    "        metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "        \n",
    "        \n",
    "        # confusion matrix\n",
    "        \n",
    "        \n",
    "        metrics_dict = dict(\n",
    "            # unweighted measures\n",
    "            tpr = metrics.truePositiveRate(label=1.0),\n",
    "            fpr = metrics.falsePositiveRate(label=1.0),\n",
    "            precision = metrics.precision(label=1.0),\n",
    "            recall = metrics.recall(label=1.0),\n",
    "            fMeasure = metrics.fMeasure(label=1.0)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        metrics_dict= {k:round(v,3) if  k != \"confusion\" else v for k,v in metrics_dict.items()}\n",
    "        \n",
    "        \n",
    "        return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-soundtrack",
   "metadata": {},
   "source": [
    "# Setup Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "indie-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "\"verbose\": True,\n",
    "\"gt_column\": \"income\",\n",
    "\n",
    "\"hyperopt\":\n",
    "    {\n",
    "    \"metric\": \"fMeasure\",\n",
    "    \"max_evals\": 10,\n",
    "    },\n",
    "    \n",
    "\"mlflow\":\n",
    "    {\n",
    "        \"experiment_name\": \"DEMO\",\n",
    "        \"tags\": {\"version\": \"0.1.0\"} \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-asian",
   "metadata": {},
   "source": [
    "## Initialize DataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "correct-superior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_endpoint is 10.2.3.167:9000\n"
     ]
    }
   ],
   "source": [
    "dm = DataManager(provider=\"gcp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-athens",
   "metadata": {},
   "source": [
    "## Load Features from DataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faced-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfs = {}\n",
    "\n",
    "for mode in [\"train\", \"test\"]:\n",
    "    dfs[mode] = dm.load_table(name=f\"income_transformed_data_{mode}\", store=\"feature\", partition=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pressing-trail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: double]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ranking-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlflow_client = toniq.MlflowClient()\n",
    "      \n",
    "\n",
    "def train_and_eval(model_config, args):\n",
    "    \n",
    "    '''update the model config'''\n",
    "    config[\"model\"] = model_config\n",
    "    \n",
    "    '''get the model'''\n",
    "    model = getattr(getattr(pyspark.ml, model_config[\"type\"]), model_config[\"name\"])\n",
    "    model = model(**model_config[\"params\"])\n",
    "\n",
    "    \n",
    "    '''Initialize MLFLOW Experiment (If it does not exist)'''\n",
    "    # get the experiment if it exists, otherwise it will return a None\n",
    "    \n",
    "    experiment= mlflow_client.get_experiment_by_name(config[\"mlflow\"][\"experiment_name\"])\n",
    "\n",
    "    if experiment:\n",
    "        # if the experiment is not None, get the id\n",
    "        experiment_id = experiment.experiment_id\n",
    "    else:\n",
    "        # if the experiment is None, create a new exerpiment and get the experiment by name\n",
    "        experiment_id= mlflow_client.create_experiment(config[\"mlflow\"][\"experiment_name\"])\n",
    "        experiment= mlflow_client.get_experiment_by_name(config[\"mlflow\"][\"experiment_name\"])\n",
    "\n",
    "        \n",
    "    \"\"\"CREATE A NEW RUN\"\"\"\n",
    "    current_run = mlflow_client.create_run(experiment_id)\n",
    "    run_id = current_run.info.run_id\n",
    "    \n",
    "    \n",
    "    '''FIT MODEL ON TRAINING DATASET'''\n",
    "    model = model.fit(dfs[\"train\"])\n",
    "    pred_dfs = {mode:model.transform(df) for mode, df in dfs.items()}\n",
    "    \n",
    "    \n",
    "    '''CALCULATE MODEL METRICS FOR TRAINING/TESTING SETS'''\n",
    "    metric_results= {mode: calculate_metrics(pred_df) for mode,pred_df in pred_dfs.items()}\n",
    "                \n",
    "    '''Register Metrics'''\n",
    "    for mode in metric_results.keys():\n",
    "        for metric_key, metric_val in metric_results[mode].items():\n",
    "            mlflow_client.log_metric(run_id, f\"{mode}-{metric_key}\", metric_val)\n",
    "    \n",
    "    for param_name, param_val in config[\"model\"][\"params\"].items():\n",
    "        mlflow_client.log_param(run_id,param_name, param_val)\n",
    "            \n",
    "    # report metricn to tune\n",
    "    return -metric_results[\"test\"][config[\"hyperopt\"][\"metric\"]]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "powered-lotus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:29<00:00, 14.91s/trial, best loss: -0.685]\n",
      "{'maxBins_2': 58.0, 'maxDepth_2': 5.0, 'minInstancesPerNode_2': 56.0, 'model': 1}\n",
      "{'name': 'GBTClassifier', 'params': {'maxBins': 58.0, 'maxDepth': 5.0, 'minInstancesPerNode': 56.0}, 'type': 'classification'}\n"
     ]
    }
   ],
   "source": [
    "# define an objective function\n",
    "def objective(args):\n",
    "    case, val = args\n",
    "    if case == 'case 1':\n",
    "        return val\n",
    "    else:\n",
    "        return val ** 2\n",
    "\n",
    "# define a search space\n",
    "\n",
    "\n",
    "{\n",
    "    'type': 'classification',\n",
    "    'name': 'RandomForestClassifier',    \n",
    "    'params': dict(maxDepth=10, maxBins=49, minInstancesPerNode=2, numTrees= 10)\n",
    "    }\n",
    "\n",
    "space = hp.choice('model',\n",
    "    \"\"\"\n",
    "    Chosing the Mode\n",
    "    \"\"\"\n",
    "                \n",
    "    [\n",
    "        {\n",
    "            'type': 'classification',\n",
    "            'name': 'RandomForestClassifier',    \n",
    "            'params': {\n",
    "                       \"maxDepth\":hp.quniform(\"maxDepth\",5,10,1),\n",
    "                       \"maxBins\":hp.quniform(\"maxBins\", 45,60,1),\n",
    "                       \"minInstancesPerNode\":hp.quniform(\"minInstancesPerNode\", 40,60,1),\n",
    "                       \"numTrees\":hp.quniform(\"numTrees\", 40,60,1)\n",
    "                      }\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            'type': 'classification',\n",
    "            'name': 'GBTClassifier',   \n",
    "            \n",
    "            \n",
    "            'params': {\n",
    "                       \"maxDepth\":hp.quniform(\"maxDepth_GBT\",5,10,1),\n",
    "                       \"maxBins\":hp.quniform(\"maxBins_GBT\", 45,60,1),\n",
    "                       \"minInstancesPerNode\":hp.quniform(\"minInstancesPerNode_GBT\", 40,60,1),\n",
    "                      }\n",
    "        }\n",
    "        \n",
    "\n",
    "    ])\n",
    "\n",
    "# minimize the objective over the space\n",
    "from hyperopt import fmin, tpe\n",
    "best = fmin(partial(train_and_eval, args=config), space, algo=tpe.suggest, max_evals=config[\"hyperopt\"][\"max_evals\"])\n",
    "\n",
    "print(best)\n",
    "# -> {'a': 1, 'c2': 0.01420615366247227}\n",
    "print(\"Best Hypr\", hyperopt.space_eval(space, best))\n",
    "# -> ('case 2', 0.01420615366247227}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-ceiling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toniq-python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
